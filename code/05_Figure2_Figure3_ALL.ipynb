{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import rasterio as rio\n",
    "import geopandas as gp\n",
    "\n",
    "import fiona \n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict \n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "\n",
    "from rasterio.mask import mask\n",
    "from cartopy.io.shapereader import Reader\n",
    "from cartopy.feature import ShapelyFeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D      \n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from tqdm import tqdm\n",
    "\n",
    "from osgeo import gdal, osr, ogr\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddf999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files setup dirs for Seasonal results\n",
    "gdf = gp.read_file(\"../shape/sierra_catchments.shp\")\n",
    "seasonal_dir = \"../rasters/seasonal_fin\"\n",
    "outdir = \"../rasters/seasonal_merged\"\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "# Setup iterables of seasons and vars to loop thru \n",
    "seasons = ['W','Sp','Su','F']\n",
    "p_vars = ['plag','pcor','pmi','pte','pjsd']\n",
    "d_vars = ['dlag','dcor','dmi','dte','djsd']\n",
    "\n",
    "# Clip the rasters to the watershed boundaries \n",
    "for idx, x in enumerate(gdf[:].iterrows()):\n",
    "    print(\"****\" * 15)\n",
    "\n",
    "    row  = x[1]\n",
    "    stn_id = row['stid']\n",
    "    print(\"PROCESSING : \", stn_id, row['catch_name'])\n",
    "\n",
    "    # loop through seasons \n",
    "    for season in tqdm(seasons[:]):\n",
    "        sfiles = [os.path.join(seasonal_dir,x) for x in os.listdir(seasonal_dir) if season in x and stn_id in x]\n",
    "\n",
    "        # loop through precip vars\n",
    "        for hvar in p_vars[:]:\n",
    "            \n",
    "            # setup write dir\n",
    "            vardir = os.path.join(outdir,hvar)\n",
    "            if not os.path.exists(vardir):\n",
    "                os.mkdir(vardir)\n",
    "\n",
    "            # Get the fns which match the var \n",
    "            varfiles = [x for x in sfiles if hvar in x]\n",
    "\n",
    "            # First clip rasters to shp \n",
    "            catch_shp = \"../shape/{}.shp\".format(stn_id)\n",
    "\n",
    "            # clip and write to merged/var dir (if not already done)\n",
    "            for fn in varfiles:\n",
    "                varfn = os.path.split(fn)[1]\n",
    "                outfn = os.path.join(vardir,varfn) \n",
    "                if not os.path.exists(outfn):\n",
    "                    cmd = '''gdalwarp -dstnodata -999 -cutline {} -crop_to_cutline {} {}'''.format(catch_shp, fn, outfn)\n",
    "                    os.system(cmd)                 \n",
    "                \n",
    "            # merge and write \n",
    "            dirfiles = [os.path.abspath(os.path.join(vardir,x)) for x in os.listdir(vardir) if season in x and x.endswith(\".tiff\")]\n",
    "            g = gdal.Warp(os.path.join(vardir,\"{}_{}.tiff\".format(hvar, season)), dirfiles, format=\"GTiff\")\n",
    "            g = None # Close file\n",
    "            \n",
    "        # loop through dswe vars\n",
    "        for hvar in d_vars[:]:\n",
    "            \n",
    "            # setup write dir\n",
    "            vardir = os.path.join(outdir,hvar)\n",
    "            if not os.path.exists(vardir):\n",
    "                os.mkdir(vardir)\n",
    "\n",
    "            # Get the fns which match the var \n",
    "            varfiles = [x for x in sfiles if hvar in x]\n",
    "\n",
    "            # First clip rasters to shp \n",
    "            catch_shp = \"../shape/{}.shp\".format(stn_id)\n",
    "\n",
    "            # clip and write to merged/var dir (if not already done)\n",
    "            for fn in varfiles:\n",
    "                varfn = os.path.split(fn)[1]\n",
    "                outfn = os.path.join(vardir,varfn) \n",
    "                if not os.path.exists(outfn):\n",
    "                    cmd = '''gdalwarp -dstnodata -999 -cutline {} -crop_to_cutline {} {}'''.format(catch_shp, fn, outfn)\n",
    "                    os.system(cmd)                 \n",
    "                \n",
    "            # merge and write \n",
    "            dirfiles = [os.path.abspath(os.path.join(vardir,x)) for x in os.listdir(vardir) if season in x and x.endswith(\".tiff\")]\n",
    "            g = gdal.Warp(os.path.join(vardir,\"{}_{}.tiff\".format(hvar, season)), dirfiles, format=\"GTiff\")\n",
    "            g = None # Close file\n",
    "            \n",
    "    \n",
    "    # Clean up the extra files we processed, leaving only the merged files. \n",
    "    for hvar in p_vars:\n",
    "        vardir = os.path.join(outdir,hvar)\n",
    "\n",
    "        rmfiles = [os.path.abspath(os.path.join(vardir,x)) for x in os.listdir(vardir) if len(os.path.split(x)[1]) > len(\"{}_Su.tiff\".format(hvar))]\n",
    "        for rmfile in rmfiles:\n",
    "            os.remove(rmfile)\n",
    "            \n",
    "    for hvar in d_vars:\n",
    "        vardir = os.path.join(outdir,hvar)\n",
    "\n",
    "        rmfiles = [os.path.abspath(os.path.join(vardir,x)) for x in os.listdir(vardir) if len(os.path.split(x)[1]) > len(\"{}_Su.tiff\".format(hvar))]\n",
    "        for rmfile in rmfiles:\n",
    "            os.remove(rmfile)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4902c377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4c49e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read files setup dirs for Extreme event results\n",
    "\n",
    "extreme_dirs = [\"../rasters/ranked_extremes_1d/\", \"../rasters/ranked_extremes_3d/\", \"../rasters/ranked_extremes_5d/\"]\n",
    "outdirs = [x.replace(\"extremes\",'merged') for x in extreme_dirs]\n",
    "\n",
    "# make dirs \n",
    "for outdir in outdirs:\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "\n",
    "# Setup iterables of scenarios and vars to loop thru \n",
    "scenarios = ['ex']\n",
    "p_vars = ['plag','pcor','pmi','pte','pjsd']\n",
    "d_vars = ['dlag','dcor','dmi','dte','djsd']\n",
    "\n",
    "\n",
    "for extreme_dir, outdir in zip(extreme_dirs, outdirs):\n",
    "    \n",
    "    print (extreme_dir)\n",
    "    # Clip the rasters to the watershed boundaries \n",
    "    for idx, x in enumerate(gdf[:].iterrows()):\n",
    "        print(\"****\" * 15)\n",
    "\n",
    "        row  = x[1]\n",
    "        stn_id = row['stid']\n",
    "        print(\"PROCESSING : \", stn_id, row['catch_name'])\n",
    "\n",
    "        # loop through scenarios \n",
    "        for scenario in tqdm(scenarios[:]):\n",
    "            sfiles = [os.path.join(extreme_dir,x) for x in os.listdir(extreme_dir) if scenario in x and stn_id in x]\n",
    "\n",
    "            # loop through precip vars\n",
    "            for hvar in p_vars[:]:\n",
    "\n",
    "                # setup write dir\n",
    "                vardir = os.path.join(outdir,hvar)\n",
    "                if not os.path.exists(vardir):\n",
    "                    os.mkdir(vardir)\n",
    "\n",
    "                # Get the fns which match the var \n",
    "                varfiles = [x for x in sfiles if hvar in x]\n",
    "\n",
    "                # First clip rasters to shp \n",
    "                catch_shp = \"../shape/{}.shp\".format(stn_id)\n",
    "\n",
    "                # clip and write to merged/var dir (if not already done)\n",
    "                for fn in varfiles:\n",
    "                    varfn = os.path.split(fn)[1]\n",
    "                    outfn = os.path.join(vardir,varfn) \n",
    "                    if not os.path.exists(outfn):\n",
    "                        cmd = '''gdalwarp -dstnodata -999 -cutline {} -crop_to_cutline {} {}'''.format(catch_shp, fn, outfn)\n",
    "                        os.system(cmd)                 \n",
    "\n",
    "                # merge and write \n",
    "                dirfiles = [os.path.abspath(os.path.join(vardir,x)) for x in os.listdir(vardir) if scenario in x and x.endswith(\".tiff\")]\n",
    "                g = gdal.Warp(os.path.join(vardir,\"{}_{}.tiff\".format(hvar, scenario)), dirfiles, format=\"GTiff\")\n",
    "                g = None # Close file\n",
    "\n",
    "            # loop through dswe vars\n",
    "            for hvar in d_vars[:]:\n",
    "\n",
    "                # setup write dir\n",
    "                vardir = os.path.join(outdir,hvar)\n",
    "                if not os.path.exists(vardir):\n",
    "                    os.mkdir(vardir)\n",
    "\n",
    "                # Get the fns which match the var \n",
    "                varfiles = [x for x in sfiles if hvar in x]\n",
    "\n",
    "                # First clip rasters to shp \n",
    "                catch_shp = \"../shape/{}.shp\".format(stn_id)\n",
    "\n",
    "                # clip and write to merged/var dir (if not already done)\n",
    "                for fn in varfiles:\n",
    "                    varfn = os.path.split(fn)[1]\n",
    "                    outfn = os.path.join(vardir,varfn) \n",
    "                    if not os.path.exists(outfn):\n",
    "                        cmd = '''gdalwarp -dstnodata -999 -cutline {} -crop_to_cutline {} {}'''.format(catch_shp, fn, outfn)\n",
    "                        os.system(cmd)                 \n",
    "\n",
    "                # merge and write \n",
    "                dirfiles = [os.path.abspath(os.path.join(vardir,x)) for x in os.listdir(vardir) if scenario in x and x.endswith(\".tiff\")]\n",
    "                g = gdal.Warp(os.path.join(vardir,\"{}_{}.tiff\".format(hvar, scenario)), dirfiles, format=\"GTiff\")\n",
    "                g = None # Close file\n",
    "\n",
    "        # Clean up the extra files we processed, leaving only the merged files. \n",
    "        for hvar in p_vars:\n",
    "            vardir = os.path.join(outdir,hvar)\n",
    "            rmfiles = [os.path.abspath(os.path.join(vardir,x)) for x in os.listdir(vardir) if len(os.path.split(x)[1]) > len(\"{}_nex.tiff\".format(hvar))]\n",
    "            for rmfile in rmfiles:\n",
    "                os.remove(rmfile)\n",
    "\n",
    "        for hvar in d_vars:\n",
    "            vardir = os.path.join(outdir,hvar)\n",
    "            rmfiles = [os.path.abspath(os.path.join(vardir,x)) for x in os.listdir(vardir) if len(os.path.split(x)[1]) > len(\"{}_nex.tiff\".format(hvar))]\n",
    "            for rmfile in rmfiles:\n",
    "                os.remove(rmfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd183b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa42ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf7e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers for plotting and processing\n",
    "\n",
    "var_lookup = {\n",
    "    'plag' : 'Lag (days)',\n",
    "    'dlag' : 'Lag (days)',\n",
    "    'pcor' : 'Correlation',\n",
    "    'dcor' : 'Correlation',\n",
    "    'pmi' : 'Mutual Information (nats)',\n",
    "    'dmi' : 'Mutual Information (nats)',\n",
    "    'pte' : 'Transfer Entropy (nats)',\n",
    "    'dte' : 'Transfer Entropy (nats)',\n",
    "    'pjsd' : 'Jensen Shannon Dist',\n",
    "    'djsd' : 'Jensen Shannon Dist',\n",
    "}\n",
    "\n",
    "def make_seasonal_df(array, season , var_type , var_cat ):\n",
    "    sdf = pd.DataFrame([array,[season for x in range(len(array))]]).T.dropna()\n",
    "    sdf.columns = [var_type,\"season\"]\n",
    "    sdf[\"Variable\"] = [var_cat for x in range(len(sdf))]\n",
    "    return sdf\n",
    "\n",
    "def tif2df(var_name, var_type, var_cat):\n",
    "\n",
    "    aut = rio.open(\"../rasters/seasonal_merged/{}/{}_F.tiff\".format(var_name, var_name)).read(1, masked=True)\n",
    "    win = rio.open(\"../rasters/seasonal_merged/{}/{}_W.tiff\".format(var_name, var_name)).read(1, masked=True)\n",
    "    spr = rio.open(\"../rasters/seasonal_merged/{}/{}_Sp.tiff\".format(var_name, var_name)).read(1, masked=True)\n",
    "    smr = rio.open(\"../rasters/seasonal_merged/{}/{}_Su.tiff\".format(var_name, var_name)).read(1, masked=True)\n",
    "    \n",
    "    av, wv, spv, smv = [x.data[x.data!=-999] for x in [aut,win,spr,smr]]\n",
    "\n",
    "    fdf = make_seasonal_df(av,\"Fall\",var_type,var_cat)\n",
    "    wdf = make_seasonal_df(wv,\"Winter\",var_type,var_cat)\n",
    "    spdf = make_seasonal_df(spv,\"Spring\",var_type,var_cat)\n",
    "    smdf = make_seasonal_df(smv,\"Summer\",var_type,var_cat)\n",
    "    x1df = make_seasonal_df(smv,\"1d\",var_type,var_cat)\n",
    "    x3df = make_seasonal_df(smv,\"3d\",var_type,var_cat)\n",
    "    x5df = make_seasonal_df(smv,\"5d\",var_type,var_cat)\n",
    "    \n",
    "    odf = pd.concat([fdf,wdf,spdf,smdf,x1df,x3df,x5df], axis = 0)\n",
    "    \n",
    "    return odf\n",
    "\n",
    "def tif2df(var_name, var_type, var_cat):\n",
    "\n",
    "    aut = rio.open(\"../rasters/seasonal_merged/{}/{}_F.tiff\".format(var_name, var_name)).read(1, masked=True)\n",
    "    win = rio.open(\"../rasters/seasonal_merged/{}/{}_W.tiff\".format(var_name, var_name)).read(1, masked=True)\n",
    "    spr = rio.open(\"../rasters/seasonal_merged/{}/{}_Sp.tiff\".format(var_name, var_name)).read(1, masked=True)\n",
    "    smr = rio.open(\"../rasters/seasonal_merged/{}/{}_Su.tiff\".format(var_name, var_name)).read(1, masked=True)\n",
    "\n",
    "    s1d = rio.open(\"../rasters/ranked_merged_1d/{}/{}_ex.tiff\".format(var_name, var_name)).read(1, masked=True)\n",
    "    s3d = rio.open(\"../rasters/ranked_merged_3d/{}/{}_ex.tiff\".format(var_name, var_name)).read(1, masked=True)\n",
    "    s5d = rio.open(\"../rasters/ranked_merged_5d/{}/{}_ex.tiff\".format(var_name, var_name)).read(1, masked=True)\n",
    "    \n",
    "    av, wv, spv, smv, x1v, x2v, x3v = [x.data[x.data!=-999] for x in [aut,win,spr,smr,s1d,s3d,s5d]]\n",
    "\n",
    "    fdf = make_seasonal_df(av,\"Fall\",var_type,var_cat)\n",
    "    wdf = make_seasonal_df(wv,\"Winter\",var_type,var_cat)\n",
    "    spdf = make_seasonal_df(spv,\"Spring\",var_type,var_cat)\n",
    "    smdf = make_seasonal_df(smv,\"Summer\",var_type,var_cat)\n",
    "    \n",
    "    x1df = make_seasonal_df(smv,\"1d\",var_type,var_cat)\n",
    "    x3df = make_seasonal_df(smv,\"3d\",var_type,var_cat)\n",
    "    x5df = make_seasonal_df(smv,\"5d\",var_type,var_cat)\n",
    "\n",
    "    odf = pd.concat([fdf,wdf,spdf,smdf, x1df, x3df, x5df], axis = 0)\n",
    "    \n",
    "    return odf\n",
    "\n",
    "def plot_basemaps(image, shp, title = None, cmap = 'viridis', ax = None, latlabels = True, lonlabels = True, vmax = None):\n",
    "    imextent = gp.read_file(shp).set_crs(\"EPSG:4326\").to_crs(4326).total_bounds\n",
    "    shape_feature = ShapelyFeature(Reader(\"../shape/sierra_catchments.shp\").geometries(),\n",
    "                        ccrs.PlateCarree(), edgecolor='white', facecolor = 'none')\n",
    "\n",
    "    minx, miny, maxx, maxy = imextent\n",
    "    lllon, lllat = minx, miny\n",
    "    urlon, urlat = maxx, maxy\n",
    "\n",
    "    # Create a Stamen Terrain instance.\n",
    "    stamen_terrain = cimgt.Stamen('terrain-background')\n",
    "\n",
    "    # Create a GeoAxes in the tile's projection.\n",
    "    gl = ax.gridlines(draw_labels=True)\n",
    "    gl.top_labels= False\n",
    "    gl.right_labels = False\n",
    "    if not latlabels:\n",
    "        gl.left_labels = False\n",
    "    if not lonlabels:\n",
    "        gl.bottom_labels = False\n",
    "        \n",
    "    gl.xlocator = mticker.FixedLocator(np.linspace(-180,180,361))\n",
    "    gl.ylocator = mticker.FixedLocator(np.linspace(0,90,91))\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlabel_style = {'size': 9, 'color': 'gray'}\n",
    "    gl.ylabel_style = {'size': 9, 'color': 'gray'}\n",
    "\n",
    "    # Limit the extent of the map to a small longitude/latitude range.\n",
    "    ax.set_extent([lllon, urlon, lllat, urlat])\n",
    "\n",
    "    # Add the Stamen data at zoom level 8.\n",
    "    ax.add_image(stamen_terrain, 8)\n",
    "    \n",
    "    im = ax.imshow(image,\n",
    "        cmap=cmap, zorder=1, vmin = 0, vmax = vmax,\n",
    "        origin=\"upper\", alpha = 0.8,\n",
    "        extent=(lllon, urlon, lllat, urlat),\n",
    "        transform=ccrs.PlateCarree(),\n",
    "    )\n",
    "\n",
    "    # Add shapefile outline\n",
    "    ax.add_feature(shape_feature, zorder = 2)\n",
    "    \n",
    "    # Set the title\n",
    "    ax.set_title(\"{}\".format(title), size = 12)\n",
    "    \n",
    "#     cbar = plt.colorbar(mappable=im,orientation='vertical', fraction=0.05, pad = 0.0125, ax = ax)\n",
    "    return im\n",
    "\n",
    "def read_tifs(var_name,season = \"F\"):\n",
    "    arr = rio.open(\"../rasters/seasonal_merged/{}/{}_{}.tiff\".format(var_name, var_name, season)).read(1, masked=True)\n",
    "    return arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed56361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ext_tifs(var_name,scenario = \"1d\"):\n",
    "    arr = rio.open(\"../rasters/ranked_merged_{}/{}/{}_ex.tiff\".format(scenario,var_name, var_name)).read(1, masked=True)\n",
    "    return arr\n",
    "\n",
    "def reject_outliers(data, m = 2.):\n",
    "    d = np.abs(data - np.median(data))\n",
    "    mdev = np.median(d)\n",
    "    s = d/mdev if mdev else 0.\n",
    "    return data[s<m]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f9b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d9f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot maps and boxplots for each season/scenario and each var "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e63e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "catchments = \"../shape/sierra_catchments.shp\"\n",
    "\n",
    "for pvar ,dvar in zip(p_vars[:1], d_vars[:1]):\n",
    "    print(pvar, dvar)\n",
    "    \n",
    "    # Extract the mean ims for each season \n",
    "    ims_p = {}\n",
    "    ims_d = {}\n",
    "    for seas in [\"F\", \"W\", \"Sp\", \"Su\"]:\n",
    "        p_sarr = read_tifs(pvar,seas)\n",
    "        d_sarr = read_tifs(dvar,seas)\n",
    "        ims_p[seas] = p_sarr\n",
    "        ims_d[seas] = d_sarr\n",
    "        \n",
    "    for scenario in [\"1d\", \"3d\", \"5d\"]:\n",
    "        p_sarr = read_ext_tifs(pvar, scenario)\n",
    "        d_sarr = read_ext_tifs(dvar, scenario)\n",
    "        ims_p[scenario] = p_sarr\n",
    "        ims_d[scenario] = d_sarr\n",
    "    \n",
    "    # Calc max for plotting colorbars\n",
    "    pmax = [np.nanmax(x) for k,x in ims_d.items()]\n",
    "    dmax = [np.nanmax(x) for k,x in ims_p.items()]\n",
    "    allmax = reject_outliers(np.array(pmax+dmax))\n",
    "    \n",
    "    vm = np.nanmax(allmax)\n",
    "    \n",
    "    # Plot \n",
    "    fig, axes = plt.subplots(nrows=2, ncols=7,figsize = (20,12), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    im = plot_basemaps(ims_p['F'], catchments, \"Fall \" + var_lookup[dvar], cmap = 'viridis', ax = axes[0][0], latlabels = True, lonlabels = False, vmax = vm)\n",
    "    plot_basemaps(ims_d['F'], catchments, \"\", cmap = 'viridis', ax = axes[1][0], latlabels = True, lonlabels = True, vmax = vm)\n",
    "\n",
    "    plot_basemaps(ims_p['W'], catchments, \"Winter \" + var_lookup[dvar], cmap = 'viridis', ax = axes[0][1], latlabels = False, lonlabels = False, vmax = vm)\n",
    "    plot_basemaps(ims_d['W'], catchments, \"\", cmap = 'viridis', ax = axes[1][1], latlabels = False, lonlabels = True, vmax = vm)\n",
    "\n",
    "    plot_basemaps(ims_p['Sp'], catchments, \"Spring \" + var_lookup[dvar], cmap = 'viridis', ax = axes[0][2], latlabels = False, lonlabels = False, vmax = vm)\n",
    "    plot_basemaps(ims_d['Sp'], catchments, \"\", cmap = 'viridis', ax = axes[1][2], latlabels = False, lonlabels = True, vmax = vm)\n",
    "\n",
    "    plot_basemaps(ims_p['Su'], catchments, \"Summer \" + var_lookup[dvar], cmap = 'viridis', ax = axes[0][3], latlabels = False, lonlabels = False, vmax = vm)\n",
    "    plot_basemaps(ims_d['Su'], catchments, \"\", cmap = 'viridis', ax = axes[1][3], latlabels = False, lonlabels = True, vmax = vm)\n",
    "\n",
    "    plot_basemaps(ims_p['1d'], catchments, \"1day sum \" + var_lookup[dvar], cmap = 'viridis', ax = axes[0][4], latlabels = False, lonlabels = False, vmax = vm)\n",
    "    plot_basemaps(ims_d['1d'], catchments, \"\", cmap = 'viridis', ax = axes[1][4], latlabels = False, lonlabels = True, vmax = vm)\n",
    "    \n",
    "    plot_basemaps(ims_p['3d'], catchments, \"3day sum \" + var_lookup[dvar], cmap = 'viridis', ax = axes[0][5], latlabels = False, lonlabels = False, vmax = vm)\n",
    "    plot_basemaps(ims_d['3d'], catchments, \"\", cmap = 'viridis', ax = axes[1][5], latlabels = False, lonlabels = True, vmax = vm)\n",
    "    \n",
    "    plot_basemaps(ims_p['5d'], catchments, \"5day sum \" + var_lookup[dvar], cmap = 'viridis', ax = axes[0][6], latlabels = False, lonlabels = False, vmax = vm)\n",
    "    plot_basemaps(ims_d['5d'], catchments, \"\", cmap = 'viridis', ax = axes[1][6], latlabels = False, lonlabels = True, vmax = vm)\n",
    "    \n",
    "    for ax, row in zip(axes[:,0], ['Precipitation', 'Snowmelt']):\n",
    "        ax.set_ylabel(row, rotation=90, size='large')\n",
    "        \n",
    "    fig.subplots_adjust(wspace=0.00,hspace =0.00)\n",
    "\n",
    "#     axes[1][0].set_ylabel(\"Precipitation\")\n",
    "#     axes[1][1].set_ylabel(\"Snowmelt\")\n",
    "    \n",
    "#     fig.subplots_adjust(right=0.8)\n",
    "#     cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "#     fig.colorbar(im, cax=cbar_ax)\n",
    "    \n",
    "    fig.colorbar(mappable = im, orientation='vertical', fraction=0.05, pad = 0.0125, ax = axes)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot boxplots of means \n",
    "    pdf = tif2df(pvar,var_type = var_lookup[pvar], var_cat = \"Precip\")\n",
    "    sdf = tif2df(dvar,var_type = var_lookup[dvar], var_cat = \"Snowmelt\")\n",
    "    \n",
    "    comdf = pd.concat([pdf,sdf], axis = 0)\n",
    "    \n",
    "    plt.figure(figsize=(8,3))\n",
    "    sns.boxplot(x=\"season\", y=var_lookup[dvar],hue=\"Variable\",data=comdf,\n",
    "                 showfliers = False, palette=['cornflowerblue','lightgray']).legend(loc='best')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eb1315",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.season.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dad8f6a",
   "metadata": {},
   "source": [
    "# Create elevation contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48664f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src = rio.open(\"../rasters/hu6_srtm_dem.tif\")\n",
    "arr = src.read(1)\n",
    "plt.imshow(arr)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8906c8e6",
   "metadata": {},
   "source": [
    "# Cd into the ../rasters and run: \n",
    "\n",
    "\n",
    "```gdal_contour -a 'elev' hu6_srtm_dem.tif ../shape/contours_500m.shp -i 500.0 -p```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd67715d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba244d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read contours we made \n",
    "cont_gdf = gp.read_file(\"../shape/contours_500m.shp\")\n",
    "cont_gdf['elev'] = np.linspace(250,4750,10) # [int(x) * 500 for x in gdf['ID']] \n",
    "\n",
    "# Set alpha val in cmap\n",
    "cmap = plt.get_cmap('viridis')\n",
    "cmap.set_under('k', alpha=0)\n",
    "\n",
    "# plot with watersehds \n",
    "ax = cont_gdf.plot(figsize = (15,10), column= 'elev',cmap = cmap, legend = True, vmin = 751)\n",
    "plt.title('500m elevation contours ')\n",
    "gp.read_file(\"../shape/sierra_catchments.shp\").plot(ax = ax, facecolor = \"none\", edgecolor = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69836bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cont_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 500m contour interval \n",
    "\n",
    "heights = np.linspace(0,5000,11)\n",
    "heights = [\"{} - {}\".format(str(x-500), str(x)) for x in heights]\n",
    "heights[0] = \"<0\"\n",
    "\n",
    "median_hts = np.linspace(250,4750,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a2cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each contour interval shape\n",
    "\n",
    "with fiona.open(\"../shape/contours_500m.shp\", \"r\") as shapefile:\n",
    "    shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    "len(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192d8ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Setup dicts to house final results\n",
    "season_res_p = {}\n",
    "season_res_d = {}\n",
    "\n",
    "# loop through seasons\n",
    "for season in seasons[:]: \n",
    "    \n",
    "    # setup dict for seasonal results\n",
    "    variable_res_p = {}\n",
    "    variable_res_d = {}\n",
    "    \n",
    "    # loop through precip vars \n",
    "    for hvarname in tqdm(p_vars[:]):\n",
    "                \n",
    "        # find the merged file\n",
    "        vardir = os.path.join(\"../rasters/seasonal_merged\",hvarname)\n",
    "        seasonal_var_fn = [os.path.join(vardir,x) for x in os.listdir(vardir) if season in x]\n",
    "        \n",
    "        # Set up dict for elevation results\n",
    "        elev_res = {}\n",
    "        \n",
    "        # Loop through elevation contours\n",
    "        for idx, shape in enumerate(shapes):\n",
    "            with rasterio.open(seasonal_var_fn[0]) as src:\n",
    "                out_image, out_transform = rasterio.mask.mask(src, [shape], crop=True)\n",
    "                outim = out_image.reshape(out_image.shape[1],out_image.shape[2])\n",
    "                outim[outim==-999]=np.nan #mask nodata vals \n",
    "                \n",
    "                elev_res[heights[idx]] = outim[~np.isnan(outim)].flatten()\n",
    "                \n",
    "        # Compile summary stats for each elevation bin \n",
    "        df_rows = []\n",
    "        for k,v in elev_res.items():\n",
    "            varmean = np.nanmean(v)\n",
    "            varstd = np.nanstd(v)\n",
    "            var_n = len(v)\n",
    "            sumdf = pd.DataFrame([k,varmean,varstd,var_n]).T\n",
    "            sumdf.columns = ['elev','{}_mean'.format(hvarname),'{}_std'.format(hvarname),'{}_num'.format(hvarname)]\n",
    "            df_rows.append(sumdf)\n",
    "            \n",
    "        # Concat the stats we just extracted \n",
    "        tdf = pd.concat(df_rows)\n",
    "        tdf['elev'] = np.linspace(250,4750,10)\n",
    "        tdf = tdf.astype(float).set_index(\"elev\")\n",
    "        \n",
    "        variable_res_p[hvarname] = tdf\n",
    "        \n",
    "    seasonal_df_p = pd.concat([v for k,v in variable_res_p.items()], axis = 1)\n",
    "    season_res_p[season] = seasonal_df_p\n",
    "    \n",
    "    \n",
    "    # loop through dswe vars \n",
    "    for hvarname in tqdm(d_vars[:]):\n",
    "                \n",
    "        # find the merged file\n",
    "        vardir = os.path.join(\"../rasters/seasonal_merged\",hvarname)\n",
    "        seasonal_var_fn = [os.path.join(vardir,x) for x in os.listdir(vardir) if season in x]\n",
    "        \n",
    "        # Set up dict for elevation results\n",
    "        elev_res = {}\n",
    "        \n",
    "        # Loop through elevation contours\n",
    "        for idx, shape in enumerate(shapes):\n",
    "            with rasterio.open(seasonal_var_fn[0]) as src:\n",
    "                out_image, out_transform = rasterio.mask.mask(src, [shape], crop=True)\n",
    "                outim = out_image.reshape(out_image.shape[1],out_image.shape[2])\n",
    "                outim[outim==-999]=np.nan #mask nodata vals \n",
    "                \n",
    "                elev_res[heights[idx]] = outim[~np.isnan(outim)].flatten()\n",
    "                \n",
    "        # Compile summary stats for each elevation bin \n",
    "        df_rows = []\n",
    "        for k,v in elev_res.items():\n",
    "            varmean = np.nanmean(v)\n",
    "            varstd = np.nanstd(v)\n",
    "            var_n = len(v)\n",
    "            sumdf = pd.DataFrame([k,varmean,varstd,var_n]).T\n",
    "            sumdf.columns = ['elev','{}_mean'.format(hvarname),'{}_std'.format(hvarname),'{}_num'.format(hvarname)]\n",
    "            df_rows.append(sumdf)\n",
    "            \n",
    "        # Concat the stats we just extracted \n",
    "        tdf = pd.concat(df_rows)\n",
    "        tdf['elev'] = np.linspace(250,4750,10)\n",
    "        tdf = tdf.astype(float).set_index(\"elev\")\n",
    "        \n",
    "        variable_res_d[hvarname] = tdf\n",
    "        \n",
    "    seasonal_df_d = pd.concat([v for k,v in variable_res_d.items()], axis = 1)\n",
    "    season_res_d[season] = seasonal_df_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=4, sharey=True, figsize=(14, 3))\n",
    "\n",
    "ax0.set_title(\"P - Q Lag\")\n",
    "\n",
    "ax0.errorbar(season_res_p['F']['plag_mean'], season_res_p['F'].index, xerr =season_res_p['F']['plag_std'],label = 'Fall', color = 'brown',marker='o' )\n",
    "ax0.errorbar(season_res_p['W']['plag_mean'], season_res_p['F'].index, xerr =season_res_p['W']['plag_std'],label = 'Winter', color = 'blue',marker='o' )\n",
    "ax0.errorbar(season_res_p['Sp']['plag_mean'], season_res_p['F'].index, xerr =season_res_p['Sp']['plag_std'],label = 'Spring', color = 'green',marker='o' )\n",
    "ax0.errorbar(season_res_p['Su']['plag_mean'], season_res_p['F'].index, xerr =season_res_p['Su']['plag_std'],label = 'Summer', color = 'red',marker='o' )\n",
    "\n",
    "ax0.set_ylabel(\"elevation(m)\")\n",
    "ax0.set_xlabel(\"Lag (days)\")\n",
    "\n",
    "ax0.legend()\n",
    "\n",
    "ax0.legend(loc='upper center', bbox_to_anchor=(0.55, -.25), ncol=4, fancybox=True, shadow=True)\n",
    "\n",
    "\n",
    "ax1.set_title(\"P - Q Correlation\")\n",
    "\n",
    "ax1.errorbar(season_res_p['F']['pcor_mean'], season_res_p['F'].index, xerr =season_res_p['F']['pcor_std'],color = 'brown',marker='o' )\n",
    "ax1.errorbar(season_res_p['W']['pcor_mean'], season_res_p['F'].index, xerr =season_res_p['F']['pcor_std'], color = 'blue',marker='o' )\n",
    "ax1.errorbar(season_res_p['Sp']['pcor_mean'], season_res_p['F'].index, xerr =season_res_p['F']['pcor_std'], color = 'green',marker='o' )\n",
    "ax1.errorbar(season_res_p['Su']['pcor_mean'], season_res_p['F'].index, xerr =season_res_p['F']['pcor_std'], color = 'red',marker='o' )\n",
    "\n",
    "ax1.set_xlabel(\"Correlation\")\n",
    "\n",
    "ax2.set_title(\"P - Q MI\")\n",
    "\n",
    "ax2.errorbar(season_res_p['F']['pmi_mean'], season_res_p['F'].index, xerr =season_res_p['F']['pmi_std'],color = 'brown',marker='o' )\n",
    "ax2.errorbar(season_res_p['W']['pmi_mean'], season_res_p['F'].index, xerr =season_res_p['W']['pmi_std'], color = 'blue',marker='o' )\n",
    "ax2.errorbar(season_res_p['Sp']['pmi_mean'], season_res_p['F'].index, xerr =season_res_p['Sp']['pmi_std'], color = 'green',marker='o' )\n",
    "ax2.errorbar(season_res_p['Su']['pmi_mean'], season_res_p['F'].index, xerr =season_res_p['Su']['pmi_std'], color = 'red',marker='o' )\n",
    "\n",
    "ax2.set_xlabel(\"MI\")\n",
    "\n",
    "ax3.set_title(\"P - Q TE\")\n",
    "\n",
    "ax3.errorbar(season_res_p['F']['pte_mean'], season_res_p['F'].index, xerr = season_res_p['F']['pte_std'],color = 'brown',marker='o' )\n",
    "ax3.errorbar(season_res_p['W']['pte_mean'], season_res_p['F'].index, xerr = season_res_p['W']['pte_std'], color = 'blue',marker='o' )\n",
    "ax3.errorbar(season_res_p['Sp']['pte_mean'], season_res_p['F'].index, xerr = season_res_p['Sp']['pte_std'], color = 'green',marker='o' )\n",
    "ax3.errorbar(season_res_p['Su']['pte_mean'], season_res_p['F'].index, xerr = season_res_p['Su']['pte_std'], color = 'red',marker='o' )\n",
    "\n",
    "ax3.set_xlabel(\"TE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883bb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04dbbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=4, sharey=True, figsize=(20, 3))\n",
    "\n",
    "ax0.set_title(\"d - Q Lag\")\n",
    "\n",
    "ax0.errorbar(season_res_d['F']['dlag_mean'], season_res_d['F'].index, xerr =season_res_d['F']['dlag_std'],label = 'Fall', color = 'brown',marker='o' )\n",
    "ax0.errorbar(season_res_d['W']['dlag_mean'], season_res_d['F'].index, xerr =season_res_d['W']['dlag_std'],label = 'Winter', color = 'blue',marker='o' )\n",
    "ax0.errorbar(season_res_d['Sp']['dlag_mean'], season_res_d['F'].index, xerr =season_res_d['Sp']['dlag_std'],label = 'Spring', color = 'green',marker='o' )\n",
    "ax0.errorbar(season_res_d['Su']['dlag_mean'], season_res_d['F'].index, xerr =season_res_d['Su']['dlag_std'],label = 'Summer', color = 'red',marker='o' )\n",
    "\n",
    "ax0.set_ylabel(\"elevation(m)\")\n",
    "ax0.set_xlabel(\"Lag (days)\")\n",
    "\n",
    "ax0.legend()\n",
    "\n",
    "ax0.legend(loc='upper center', bbox_to_anchor=(0.55, -.25), ncol=4, fancybox=True, shadow=True)\n",
    "\n",
    "\n",
    "ax1.set_title(\"d - Q Correlation\")\n",
    "\n",
    "ax1.errorbar(season_res_d['F']['dcor_mean'], season_res_d['F'].index, xerr =season_res_d['F']['dcor_std'],color = 'brown',marker='o' )\n",
    "ax1.errorbar(season_res_d['W']['dcor_mean'], season_res_d['F'].index, xerr =season_res_d['F']['dcor_std'], color = 'blue',marker='o' )\n",
    "ax1.errorbar(season_res_d['Sp']['dcor_mean'], season_res_d['F'].index, xerr =season_res_d['F']['dcor_std'], color = 'green',marker='o' )\n",
    "ax1.errorbar(season_res_d['Su']['dcor_mean'], season_res_d['F'].index, xerr =season_res_d['F']['dcor_std'], color = 'red',marker='o' )\n",
    "\n",
    "ax1.set_xlabel(\"Correlation\")\n",
    "\n",
    "ax2.set_title(\"d - Q MI\")\n",
    "\n",
    "ax2.errorbar(season_res_d['F']['dmi_mean'], season_res_d['F'].index, xerr =season_res_d['F']['dmi_std'],color = 'brown',marker='o' )\n",
    "ax2.errorbar(season_res_d['W']['dmi_mean'], season_res_d['F'].index, xerr =season_res_d['W']['dmi_std'], color = 'blue',marker='o' )\n",
    "ax2.errorbar(season_res_d['Sp']['dmi_mean'], season_res_d['F'].index, xerr =season_res_d['Sp']['dmi_std'], color = 'green',marker='o' )\n",
    "ax2.errorbar(season_res_d['Su']['dmi_mean'], season_res_d['F'].index, xerr =season_res_d['Su']['dmi_std'], color = 'red',marker='o' )\n",
    "\n",
    "ax2.set_xlabel(\"MI\")\n",
    "\n",
    "ax3.set_title(\"d - Q TE\")\n",
    "\n",
    "ax3.errorbar(season_res_d['F']['dte_mean'], season_res_d['F'].index, xerr = season_res_d['F']['dte_std'],color = 'brown',marker='o' )\n",
    "ax3.errorbar(season_res_d['W']['dte_mean'], season_res_d['F'].index, xerr = season_res_d['W']['dte_std'], color = 'blue',marker='o' )\n",
    "ax3.errorbar(season_res_d['Sp']['dte_mean'], season_res_d['F'].index, xerr = season_res_d['Sp']['dte_std'], color = 'green',marker='o' )\n",
    "ax3.errorbar(season_res_d['Su']['dte_mean'], season_res_d['F'].index, xerr = season_res_d['Su']['dte_std'], color = 'red',marker='o' )\n",
    "\n",
    "ax3.set_xlabel(\"TE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "numcols_d = [x for x in season_res_d['Su'].columns if \"num\" in x]\n",
    "\n",
    "numdfs_d = []\n",
    "\n",
    "for season in seasons:\n",
    "    sdf = pd.DataFrame(season_res_d[season][numcols_d].mean(axis = 1))\n",
    "    sdf.columns = [season]\n",
    "    numdfs_d.append(sdf)\n",
    "    \n",
    "seasdf_d = pd.concat(numdfs_d, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd1d78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all metrics as f(elevation) for SNOWMELT\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "\n",
    "ax0 = plt.subplot(151)\n",
    "ax0.set_title(\"SMLT - Q Lag\")\n",
    "varmean = pd.concat([season_res_d[key]['dlag_mean'] for key in season_res_d.keys()], axis=1).mean(axis = 1)\n",
    "varstd = pd.concat([season_res_d[key]['dlag_mean'] for key in season_res_d.keys()], axis=1).std(axis = 1)\n",
    "ax0.errorbar(varmean,varmean.index, xerr = varstd, color = 'black', label = 'Annual mean', linewidth = 2,marker='o')\n",
    "ax0.errorbar(season_res_d['F']['dlag_mean'], season_res_d['F'].index, xerr =season_res_d['F']['dlag_std'],label = 'Fall', color = 'brown', alpha = 0.4)\n",
    "ax0.errorbar(season_res_d['W']['dlag_mean'], season_res_d['F'].index, xerr =season_res_d['W']['dlag_std'],label = 'Winter', color = 'blue',alpha = 0.4 )\n",
    "ax0.errorbar(season_res_d['Sp']['dlag_mean'], season_res_d['F'].index, xerr =season_res_d['Sp']['dlag_std'],label = 'Spring', color = 'green',alpha = 0.4 )\n",
    "ax0.errorbar(season_res_d['Su']['dlag_mean'], season_res_d['F'].index, xerr =season_res_d['Su']['dlag_std'],label = 'Summer', color = 'red', alpha = 0.4 )\n",
    "\n",
    "ax0.set_ylabel(\"elevation(m)\")\n",
    "ax0.set_xlabel(\"Lag (days)\")\n",
    "\n",
    "ax0.legend()\n",
    "\n",
    "ax0.legend(loc='upper center', bbox_to_anchor=(1.25, -.25), ncol=5, fontsize = 12, fancybox=True, shadow=True)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(152)\n",
    "ax1.set_title(\"SMLT - Q Correlation\")\n",
    "varmean = pd.concat([season_res_d[key]['dcor_mean'] for key in season_res_d.keys()], axis=1).mean(axis = 1)\n",
    "varstd = pd.concat([season_res_d[key]['dcor_mean'] for key in season_res_d.keys()], axis=1).std(axis = 1)\n",
    "ax1.errorbar(varmean,varmean.index, xerr = varstd, color = 'black', label = 'Annual mean', linewidth = 2,marker='o')\n",
    "ax1.errorbar(season_res_d['F']['dcor_mean'], season_res_d['F'].index, xerr =season_res_d['F']['dcor_std'],color = 'brown', alpha = 0.4)\n",
    "ax1.errorbar(season_res_d['W']['dcor_mean'], season_res_d['F'].index, xerr =season_res_d['F']['dcor_std'], color = 'blue', alpha = 0.4)\n",
    "ax1.errorbar(season_res_d['Sp']['dcor_mean'], season_res_d['F'].index, xerr =season_res_d['F']['dcor_std'], color = 'green', alpha = 0.4 )\n",
    "ax1.errorbar(season_res_d['Su']['dcor_mean'], season_res_d['F'].index, xerr =season_res_d['F']['dcor_std'], color = 'red', alpha = 0.4)\n",
    "ax1.set(yticklabels=[])  \n",
    "ax1.set_xlabel(\"Correlation\")\n",
    "\n",
    "ax2 = plt.subplot(153)\n",
    "ax2.set_title(\"SMLT - Q MI\")\n",
    "varmean = pd.concat([season_res_d[key]['dmi_mean'] for key in season_res_d.keys()], axis=1).mean(axis = 1)\n",
    "varstd = pd.concat([season_res_d[key]['dmi_mean'] for key in season_res_d.keys()], axis=1).std(axis = 1)\n",
    "ax2.errorbar(varmean,varmean.index, xerr = varstd, color = 'black', label = 'Annual mean', linewidth = 2,marker='o')\n",
    "ax2.errorbar(season_res_d['F']['dmi_mean'], season_res_d['F'].index, xerr =season_res_d['F']['dmi_std'],color = 'brown', alpha = 0.4 )\n",
    "ax2.errorbar(season_res_d['W']['dmi_mean'], season_res_d['F'].index, xerr =season_res_d['W']['dmi_std'], color = 'blue', alpha = 0.4 )\n",
    "ax2.errorbar(season_res_d['Sp']['dmi_mean'], season_res_d['F'].index, xerr =season_res_d['Sp']['dmi_std'], color = 'green', alpha = 0.4 )\n",
    "ax2.errorbar(season_res_d['Su']['dmi_mean'], season_res_d['F'].index, xerr =season_res_d['Su']['dmi_std'], color = 'red', alpha = 0.4 )\n",
    "ax2.set(yticklabels=[])  \n",
    "ax2.set_xlabel(\"MI\")\n",
    "\n",
    "ax3 = plt.subplot(154)\n",
    "ax3.set_title(\"SMLT - Q TE\")\n",
    "varmean = pd.concat([season_res_d[key]['dte_mean'] for key in season_res_d.keys()], axis=1).mean(axis = 1)\n",
    "varstd = pd.concat([season_res_d[key]['dte_mean'] for key in season_res_d.keys()], axis=1).std(axis = 1)\n",
    "ax3.errorbar(varmean,varmean.index, xerr = varstd, color = 'black', label = 'Annual mean', linewidth = 2,marker='o')\n",
    "ax3.errorbar(season_res_d['F']['dte_mean'], season_res_d['F'].index, xerr = season_res_d['F']['dte_std'],color = 'brown', alpha = 0.4)\n",
    "ax3.errorbar(season_res_d['W']['dte_mean'], season_res_d['F'].index, xerr = season_res_d['W']['dte_std'], color = 'blue', alpha = 0.4)\n",
    "ax3.errorbar(season_res_d['Sp']['dte_mean'], season_res_d['F'].index, xerr = season_res_d['Sp']['dte_std'], color = 'green', alpha = 0.4)\n",
    "ax3.errorbar(season_res_d['Su']['dte_mean'], season_res_d['F'].index, xerr = season_res_d['Su']['dte_std'], color = 'red', alpha = 0.4)\n",
    "ax3.set(yticklabels=[])  \n",
    "ax3.set_xlabel(\"TE\")\n",
    "\n",
    "plt.subplot(155)\n",
    "ax4 = seasdf_d.plot(kind = 'barh', ax = plt.gca(),color = ['blue', 'green', 'red', 'brown'])\n",
    "ax4.set(yticklabels=[])  \n",
    "ax4.set_ylabel(\"\")  \n",
    "ax4.set_xlabel(\"N\")  \n",
    "ax4.set_title(\"Npixels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f958de54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe932340",
   "metadata": {},
   "outputs": [],
   "source": [
    "numcols_p = [x for x in season_res_p['Su'].columns if \"num\" in x]\n",
    "\n",
    "numdfs_p = []\n",
    "\n",
    "for season in seasons:\n",
    "    sdf = pd.DataFrame(season_res_p[season][numcols_p].mean(axis = 1))\n",
    "    sdf.columns = [season]\n",
    "    numdfs_p.append(sdf)\n",
    "    \n",
    "seasdf_p = pd.concat(numdfs_p, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6e855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all metrics as f(elevation) for Liquid Precip\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "\n",
    "ax0 = plt.subplot(151)\n",
    "ax0.set_title(\"PRCP - Q Lag\")\n",
    "varmean = pd.concat([season_res_p[key]['plag_mean'] for key in season_res_p.keys()], axis=1).mean(axis = 1)\n",
    "varstd = pd.concat([season_res_p[key]['plag_mean'] for key in season_res_p.keys()], axis=1).std(axis = 1)\n",
    "ax0.errorbar(varmean,varmean.index, xerr = varstd, color = 'black', label = 'Annual mean', linewidth = 2,marker='o')\n",
    "ax0.errorbar(season_res_p['F']['plag_mean'], season_res_p['F'].index, xerr =season_res_p['F']['plag_std'],label = 'Fall', color = 'brown',alpha = 0.4)\n",
    "ax0.errorbar(season_res_p['W']['plag_mean'], season_res_p['F'].index, xerr =season_res_p['W']['plag_std'],label = 'Winter', color = 'blue',alpha = 0.4)\n",
    "ax0.errorbar(season_res_p['Sp']['plag_mean'], season_res_p['F'].index, xerr =season_res_p['Sp']['plag_std'],label = 'Spring', color = 'green',alpha = 0.4)\n",
    "ax0.errorbar(season_res_p['Su']['plag_mean'], season_res_p['F'].index, xerr =season_res_p['Su']['plag_std'],label = 'Summer', color = 'red',alpha = 0.4)\n",
    "\n",
    "ax0.set_ylabel(\"elevation(m)\")\n",
    "ax0.set_xlabel(\"Lag (days)\")\n",
    "\n",
    "ax0.legend(loc='upper center', bbox_to_anchor=(1.25, -.25), ncol=5, fontsize = 12, fancybox=True, shadow=True)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(152)\n",
    "ax1.set_title(\"PRCP - Q Correlation\")\n",
    "varmean = pd.concat([season_res_p[key]['pcor_mean'] for key in season_res_p.keys()], axis=1).mean(axis = 1)\n",
    "varstd = pd.concat([season_res_p[key]['pcor_mean'] for key in season_res_p.keys()], axis=1).std(axis = 1)\n",
    "ax1.errorbar(varmean,varmean.index, xerr = varstd, color = 'black', label = 'Annual mean', linewidth = 2,marker='o')\n",
    "ax1.errorbar(season_res_p['F']['pcor_mean'], season_res_p['F'].index, xerr =season_res_p['F']['pcor_std'],color = 'brown',alpha = 0.4)\n",
    "ax1.errorbar(season_res_p['W']['pcor_mean'], season_res_p['F'].index, xerr =season_res_p['F']['pcor_std'], color = 'blue',alpha = 0.4)\n",
    "ax1.errorbar(season_res_p['Sp']['pcor_mean'], season_res_p['F'].index, xerr =season_res_p['F']['pcor_std'], color = 'green',alpha = 0.4)\n",
    "ax1.errorbar(season_res_p['Su']['pcor_mean'], season_res_p['F'].index, xerr =season_res_p['F']['pcor_std'], color = 'red',alpha = 0.4)\n",
    "ax1.set(yticklabels=[])  \n",
    "ax1.set_xlabel(\"Correlation\")\n",
    "\n",
    "ax2 = plt.subplot(153)\n",
    "ax2.set_title(\"PRCP - Q MI\")\n",
    "varmean = pd.concat([season_res_p[key]['pmi_mean'] for key in season_res_p.keys()], axis=1).mean(axis = 1)\n",
    "varstd = pd.concat([season_res_p[key]['pmi_mean'] for key in season_res_p.keys()], axis=1).std(axis = 1)\n",
    "ax2.errorbar(varmean,varmean.index, xerr = varstd, color = 'black', label = 'Annual mean', linewidth = 2,marker='o')\n",
    "ax2.errorbar(season_res_p['F']['pmi_mean'], season_res_p['F'].index, xerr =season_res_p['F']['pmi_std'],color = 'brown',alpha = 0.4)\n",
    "ax2.errorbar(season_res_p['W']['pmi_mean'], season_res_p['F'].index, xerr =season_res_p['W']['pmi_std'], color = 'blue',alpha = 0.4)\n",
    "ax2.errorbar(season_res_p['Sp']['pmi_mean'], season_res_p['F'].index, xerr =season_res_p['Sp']['pmi_std'], color = 'green',alpha = 0.4)\n",
    "ax2.errorbar(season_res_p['Su']['pmi_mean'], season_res_p['F'].index, xerr =season_res_p['Su']['pmi_std'], color = 'red',alpha = 0.4)\n",
    "ax2.set(yticklabels=[])  \n",
    "ax2.set_xlabel(\"MI\")\n",
    "\n",
    "ax3 = plt.subplot(154)\n",
    "ax3.set_title(\"PRCP - Q TE\")\n",
    "varmean = pd.concat([season_res_p[key]['pte_mean'] for key in season_res_p.keys()], axis=1).mean(axis = 1)\n",
    "varstd = pd.concat([season_res_p[key]['pte_mean'] for key in season_res_p.keys()], axis=1).std(axis = 1)\n",
    "ax3.errorbar(varmean,varmean.index, xerr = varstd, color = 'black', label = 'Annual mean', linewidth = 2,marker='o')\n",
    "ax3.errorbar(season_res_p['F']['pte_mean'], season_res_p['F'].index, xerr = season_res_p['F']['pte_std'],color = 'brown',alpha = 0.4)\n",
    "ax3.errorbar(season_res_p['W']['pte_mean'], season_res_p['F'].index, xerr = season_res_p['W']['pte_std'], color = 'blue',alpha = 0.4)\n",
    "ax3.errorbar(season_res_p['Sp']['pte_mean'], season_res_p['F'].index, xerr = season_res_p['Sp']['pte_std'], color = 'green',alpha = 0.4)\n",
    "ax3.errorbar(season_res_p['Su']['pte_mean'], season_res_p['F'].index, xerr = season_res_p['Su']['pte_std'], color = 'red',alpha = 0.4)\n",
    "ax3.set(yticklabels=[])  \n",
    "ax3.set_xlabel(\"TE\")\n",
    "\n",
    "plt.subplot(155)\n",
    "ax4 = seasdf_p.plot(kind = 'barh', ax = plt.gca(),color = ['blue', 'green', 'red', 'brown'])\n",
    "ax4.set(yticklabels=[])  \n",
    "ax4.set_ylabel(\"\")  \n",
    "ax4.set_xlabel(\"N\")  \n",
    "ax4.set_title(\"Npixels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e8527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7cc4b61",
   "metadata": {},
   "source": [
    "# Plot for each watershed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf25a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup dicts to house final results\n",
    "season_res_p_sheds = {}\n",
    "season_res_d_sheds = {}\n",
    "\n",
    "# Loop through watersheds \n",
    "for idx, x in enumerate(gdf[:].iterrows()):\n",
    "    \n",
    "    season_res_p = {}\n",
    "    season_res_d = {}\n",
    "    \n",
    "    print(\"****\" * 15)\n",
    "    row  = x[1]\n",
    "    stn_id = row['stid']    \n",
    "    if stn_id == \"MCR\" or stn_id == \"CFW\" or stn_id == \"NHG\":\n",
    "        continue\n",
    "        print(\"No Reservoir data for {}\".format(stn_id))\n",
    "        \n",
    "    catch_shp = \"../shape/{}.shp\".format(stn_id)\n",
    "    print(\"PROCESSING : \", stn_id, row['catch_name'])\n",
    "    \n",
    "    # Merge the contours and watershed\n",
    "    shed_elevs = gp.overlay(cont_gdf, gp.read_file(catch_shp), how='intersection')\n",
    "    if not os.path.exists(\"../shape/shed_cons\"):\n",
    "        os.mkdir(\"../shape/shed_cons\")\n",
    "    shed_elevs.to_file(\"../shape/shed_cons/{}.shp\".format(stn_id))\n",
    "    \n",
    "    # Read teh shapes \n",
    "    with fiona.open(\"../shape/shed_cons/{}.shp\".format(stn_id), \"r\") as shapefile:\n",
    "        shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "        elevs = [feature['properties']['elev'] for feature in shapefile]\n",
    "\n",
    "    # Setup dicts to house seasonal results\n",
    "    season_res_p = {}\n",
    "    season_res_d = {}\n",
    "\n",
    "    # loop through seasons\n",
    "    for season in seasons[:]: \n",
    "\n",
    "        # setup dict for seasonal results\n",
    "        variable_res_p = {}\n",
    "        variable_res_d = {}\n",
    "\n",
    "        # loop through precip vars \n",
    "        for hvarname in tqdm(p_vars[:]):\n",
    "\n",
    "            # find the merged file\n",
    "            vardir = os.path.join(\"../rasters/seasonal_merged\",hvarname)\n",
    "            seasonal_var_fn = [os.path.join(vardir,x) for x in os.listdir(vardir) if season in x]\n",
    "\n",
    "            # Set up dict for elevation results\n",
    "            elev_res = {}\n",
    "\n",
    "            # Loop through elevation contours\n",
    "            for idx, shape in enumerate(shapes):\n",
    "                with rasterio.open(seasonal_var_fn[0]) as src:\n",
    "                    out_image, out_transform = rasterio.mask.mask(src, [shape], crop=True)\n",
    "                    outim = out_image.reshape(out_image.shape[1],out_image.shape[2])\n",
    "                    outim[outim==-999]=np.nan #mask nodata vals \n",
    "\n",
    "                    elev_res[heights[idx]] = outim[~np.isnan(outim)].flatten()\n",
    "\n",
    "            # Compile summary stats for each elevation bin \n",
    "            df_rows = []\n",
    "            for k,v in elev_res.items():\n",
    "                varmean = np.nanmean(v)\n",
    "                varstd = np.nanstd(v)\n",
    "                var_n = len(v)\n",
    "                sumdf = pd.DataFrame([k,varmean,varstd,var_n]).T\n",
    "                sumdf.columns = ['elev','{}_mean'.format(hvarname),'{}_std'.format(hvarname),'{}_num'.format(hvarname)]\n",
    "                df_rows.append(sumdf)\n",
    "\n",
    "            # Concat the stats we just extracted \n",
    "            tdf = pd.concat(df_rows)\n",
    "            tdf['elev'] = elevs\n",
    "            tdf = tdf.astype(float).set_index(\"elev\")\n",
    "\n",
    "            variable_res_p[hvarname] = tdf\n",
    "\n",
    "        seasonal_df_p = pd.concat([v for k,v in variable_res_p.items()], axis = 1)\n",
    "        season_res_p[season] = seasonal_df_p\n",
    "\n",
    "\n",
    "        # loop through dswe vars \n",
    "        for hvarname in tqdm(d_vars[:]):\n",
    "\n",
    "            # find the merged file\n",
    "            vardir = os.path.join(\"../rasters/seasonal_merged\",hvarname)\n",
    "            seasonal_var_fn = [os.path.join(vardir,x) for x in os.listdir(vardir) if season in x]\n",
    "\n",
    "            # Set up dict for elevation results\n",
    "            elev_res = {}\n",
    "\n",
    "            # Loop through elevation contours\n",
    "            for idx, shape in enumerate(shapes):\n",
    "                with rasterio.open(seasonal_var_fn[0]) as src:\n",
    "                    out_image, out_transform = rasterio.mask.mask(src, [shape], crop=True)\n",
    "                    outim = out_image.reshape(out_image.shape[1],out_image.shape[2])\n",
    "                    outim[outim==-999]=np.nan #mask nodata vals \n",
    "\n",
    "                    elev_res[heights[idx]] = outim[~np.isnan(outim)].flatten()\n",
    "\n",
    "            # Compile summary stats for each elevation bin \n",
    "            df_rows = []\n",
    "            for k,v in elev_res.items():\n",
    "                varmean = np.nanmean(v)\n",
    "                varstd = np.nanstd(v)\n",
    "                var_n = len(v)\n",
    "                sumdf = pd.DataFrame([k,varmean,varstd,var_n]).T\n",
    "                sumdf.columns = ['elev','{}_mean'.format(hvarname),'{}_std'.format(hvarname),'{}_num'.format(hvarname)]\n",
    "                df_rows.append(sumdf)\n",
    "\n",
    "            # Concat the stats we just extracted \n",
    "            tdf = pd.concat(df_rows)\n",
    "            tdf['elev'] = elevs\n",
    "            tdf = tdf.astype(float).set_index(\"elev\")\n",
    "\n",
    "            variable_res_d[hvarname] = tdf\n",
    "\n",
    "        seasonal_df_d = pd.concat([v for k,v in variable_res_d.items()], axis = 1)\n",
    "        season_res_d[season] = seasonal_df_d\n",
    "        \n",
    "    season_res_d_sheds[stn_id] = season_res_d\n",
    "    season_res_p_sheds[stn_id] = season_res_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcad8963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7150cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get enough colors for each watershed to be unique\n",
    "colors = sns.color_palette(\"husl\", len(season_res_p_sheds.keys()))\n",
    "cdict = OrderedDict(zip(list(gdf[~gdf['stid'].isin(['CFW', 'MCR', 'NHG'])]['stid']),colors))\n",
    "\n",
    "\n",
    "# Setup fig\n",
    "plt.figure(figsize=(20,4))\n",
    "\n",
    "\n",
    "# Loop through results\n",
    "for k,v in season_res_p_sheds.items():\n",
    "    stid = k\n",
    "    season_res_p = v\n",
    "    varmean = pd.concat([season_res_p[key]['plag_mean'] for key in season_res_p.keys()], axis=1).mean(axis = 1)\n",
    "    varstd = pd.concat([season_res_p[key]['plag_mean'] for key in season_res_p.keys()], axis=1).std(axis = 1)\n",
    "\n",
    "    ax0 = plt.subplot(141)\n",
    "    ax0.set_title(\"PRCP - Q Lag\")\n",
    "    varmean = pd.concat([season_res_p[key]['plag_mean'] for key in season_res_p.keys()], axis=1).mean(axis = 1)\n",
    "    varstd = pd.concat([season_res_p[key]['plag_mean'] for key in season_res_p.keys()], axis=1).std(axis = 1)\n",
    "    ax0.errorbar(varmean,varmean.index, xerr = varstd, label = k, linewidth = 1,marker='o', c= cdict[stid])\n",
    "    ax0.set_ylabel(\"elevation(m)\")\n",
    "    ax0.set_xlabel(\"Lag (days)\")\n",
    "    \n",
    "    ax1 = plt.subplot(142)\n",
    "    ax1.set_title(\"PRCP - Q Correlation\")\n",
    "    varmean = pd.concat([season_res_p[key]['pcor_mean'] for key in season_res_p.keys()], axis=1).mean(axis = 1)\n",
    "    varstd = pd.concat([season_res_p[key]['pcor_mean'] for key in season_res_p.keys()], axis=1).std(axis = 1)\n",
    "    ax1.errorbar(varmean,varmean.index, xerr = varstd, label = k, linewidth = 1,marker='o',c= cdict[stid])\n",
    "    ax1.set(yticklabels=[])  \n",
    "    ax1.set_xlabel(\"Correlation\")\n",
    "\n",
    "    ax2 = plt.subplot(143)\n",
    "    ax2.set_title(\"PRCP - Q MI\")\n",
    "    varmean = pd.concat([season_res_p[key]['pmi_mean'] for key in season_res_p.keys()], axis=1).mean(axis = 1)\n",
    "    varstd = pd.concat([season_res_p[key]['pmi_mean'] for key in season_res_p.keys()], axis=1).std(axis = 1)\n",
    "    ax2.errorbar(varmean,varmean.index, xerr = varstd,  label = k, linewidth = 1,marker='o',c= cdict[stid])\n",
    "    ax2.set(yticklabels=[])  \n",
    "    ax2.set_xlabel(\"MI\")\n",
    "\n",
    "    ax3 = plt.subplot(144)\n",
    "    ax3.set_title(\"PRCP - Q TE\")\n",
    "    varmean = pd.concat([season_res_p[key]['pte_mean'] for key in season_res_p.keys()], axis=1).mean(axis = 1)\n",
    "    varstd = pd.concat([season_res_p[key]['pte_mean'] for key in season_res_p.keys()], axis=1).std(axis = 1)\n",
    "    ax3.errorbar(varmean,varmean.index, xerr = varstd,  label = k, linewidth = 1,marker='o',c= cdict[stid])\n",
    "    ax3.set(yticklabels=[])  \n",
    "    ax3.set_xlabel(\"TE\")\n",
    "\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(-0.05, -.25), ncol=6, fontsize = 14, fancybox=True, shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb05de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get enough colors for each watershed to be unique\n",
    "colors = sns.color_palette(\"husl\", len(season_res_p_sheds.keys()))\n",
    "cdict = OrderedDict(zip(list(gdf[~gdf['stid'].isin(['CFW', 'MCR', 'NHG'])]['stid']),colors))\n",
    "\n",
    "\n",
    "# Setup fig\n",
    "plt.figure(figsize=(20,4))\n",
    "\n",
    "\n",
    "# Loop through results\n",
    "for k,v in season_res_d_sheds.items():\n",
    "    stid = k\n",
    "    season_res_d = v\n",
    "    varmean = pd.concat([season_res_d[key]['dlag_mean'] for key in season_res_d.keys()], axis=1).mean(axis = 1)\n",
    "    varstd = pd.concat([season_res_d[key]['dlag_mean'] for key in season_res_d.keys()], axis=1).std(axis = 1)\n",
    "\n",
    "    ax0 = plt.subplot(141)\n",
    "    ax0.set_title(\"SMLT - Q Lag\")\n",
    "    varmean = pd.concat([season_res_d[key]['dlag_mean'] for key in season_res_d.keys()], axis=1).mean(axis = 1)\n",
    "    varstd = pd.concat([season_res_d[key]['dlag_mean'] for key in season_res_d.keys()], axis=1).std(axis = 1)\n",
    "    ax0.errorbar(varmean,varmean.index, xerr = varstd, label = k, linewidth = 1,marker='o', c= cdict[stid])\n",
    "    ax0.set_ylabel(\"elevation(m)\")\n",
    "    ax0.set_xlabel(\"Lag (days)\")\n",
    "    \n",
    "    ax1 = plt.subplot(142)\n",
    "    ax1.set_title(\"SMLT - Q Correlation\")\n",
    "    varmean = pd.concat([season_res_d[key]['dcor_mean'] for key in season_res_d.keys()], axis=1).mean(axis = 1)\n",
    "    varstd = pd.concat([season_res_d[key]['dcor_mean'] for key in season_res_d.keys()], axis=1).std(axis = 1)\n",
    "    ax1.errorbar(varmean,varmean.index, xerr = varstd, label = k, linewidth = 1,marker='o',c= cdict[stid])\n",
    "    ax1.set(yticklabels=[])  \n",
    "    ax1.set_xlabel(\"Correlation\")\n",
    "\n",
    "    ax2 = plt.subplot(143)\n",
    "    ax2.set_title(\"SMLT - Q MI\")\n",
    "    varmean = pd.concat([season_res_d[key]['dmi_mean'] for key in season_res_d.keys()], axis=1).mean(axis = 1)\n",
    "    varstd = pd.concat([season_res_d[key]['dmi_mean'] for key in season_res_d.keys()], axis=1).std(axis = 1)\n",
    "    ax2.errorbar(varmean,varmean.index, xerr = varstd,  label = k, linewidth = 1,marker='o',c= cdict[stid])\n",
    "    ax2.set(yticklabels=[])  \n",
    "    ax2.set_xlabel(\"MI\")\n",
    "\n",
    "    ax3 = plt.subplot(144)\n",
    "    ax3.set_title(\"SMLT - Q TE\")\n",
    "    varmean = pd.concat([season_res_d[key]['dte_mean'] for key in season_res_d.keys()], axis=1).mean(axis = 1)\n",
    "    varstd = pd.concat([season_res_d[key]['dte_mean'] for key in season_res_d.keys()], axis=1).std(axis = 1)\n",
    "    ax3.errorbar(varmean,varmean.index, xerr = varstd,  label = k, linewidth = 1,marker='o',c= cdict[stid])\n",
    "    ax3.set(yticklabels=[])  \n",
    "    ax3.set_xlabel(\"TE\")\n",
    "\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(-0.05, -.25), ncol=6, fontsize = 14, fancybox=True, shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c73b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942a6b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
